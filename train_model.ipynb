{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "reliable-seller",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import glob\n",
    "import copy\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "compliant-cosmetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define run parmameters\n",
    "\n",
    "transform_image_size = 224\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "pregnant-mailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data dict\n",
    "\n",
    "data_directory = \"./dataset2/dorsal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "genuine-classic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Check device\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "alert-pilot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase number of unique images by factor of 2 by horizontal flipping,\n",
    "# but cant vertically flip\n",
    "\n",
    "# Change colour channels from 0-255 to 0-1, numpy to tensors\n",
    "\n",
    "train_transformation = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(transform_image_size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        [0.485, 0.456, 0.406], # col = rgb channel\n",
    "        [0.229, 0.224, 0.225]) # row = mean deviation\n",
    "])\n",
    "\n",
    "valid_transformation = transforms.Compose([\n",
    "        transforms.Resize(transform_image_size),\n",
    "        transforms.CenterCrop(transform_image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            [0.485, 0.456, 0.406],\n",
    "            [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "opening-structure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "\n",
    "train_dataset = datasets.ImageFolder(os.path.join(data_directory, 'train'), train_transformation)\n",
    "valid_dataset = datasets.ImageFolder(os.path.join(data_directory, 'valid'), valid_transformation)\n",
    "\n",
    "# Dataloader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True, # Shuffle is True so the model is not biased to some categories\n",
    "    num_workers=4 # How many sub processes to use for loading data into ram\n",
    ")\n",
    "\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "compatible-champagne",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_root = pathlib.Path(data_directory + '/train')\n",
    "data_classes = sorted([item.name.split('/')[-1] for item in train_root.iterdir()])\n",
    "num_classes = len(data_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "still-kennedy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['female', 'male']\n"
     ]
    }
   ],
   "source": [
    "print(data_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "recreational-stomach",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Network\n",
    "\n",
    "input_channels = 512\n",
    "output_channels = num_classes # set to the number of data classes, eg: 2 (male and female)\n",
    "kernal_size = (1,1)\n",
    "stride = (1,1)\n",
    "\n",
    "conv_network = models.squeezenet1_0(True)\n",
    "for parameter in conv_network.parameters():\n",
    "            parameter.requires_grad = False\n",
    "conv_network.classifier[1] = nn.Conv2d(input_channels, output_channels, kernel_size = kernal_size, stride = stride)\n",
    "conv_network.num_classes = num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "conventional-female",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SqueezeNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (3): Fire(\n",
      "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Fire(\n",
      "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Fire(\n",
      "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (7): Fire(\n",
      "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): Fire(\n",
      "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): Fire(\n",
      "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Fire(\n",
      "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (12): Fire(\n",
      "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = conv_network.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "spare-affiliate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t classifier.1.weight\n",
      "\t classifier.1.bias\n"
     ]
    }
   ],
   "source": [
    "params_to_update = model.parameters()\n",
    "print(\"Params to learn:\")\n",
    "params_to_update = []\n",
    "for name,param in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)\n",
    "        \n",
    "optimiser = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "direct-original",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train male: 1493 \ttrain female: 3000 \ttrain count: 4493\n",
      "valid male: 463 \tvalid female: 724 \tvalid count: 1187\n"
     ]
    }
   ],
   "source": [
    "# Calc amount of training and validation images for each class\n",
    "\n",
    "train_male = len(glob.glob(data_directory + '/train/male/*.jpg'))\n",
    "train_female = len(glob.glob(data_directory + '/train/female/*.jpg'))\n",
    "train_count = train_male + train_female\n",
    "\n",
    "valid_male = len(glob.glob(data_directory + '/valid/male/*.jpg'))\n",
    "valid_female = len(glob.glob(data_directory + '/valid/female/*.jpg'))\n",
    "valid_count = valid_male + valid_female\n",
    "\n",
    "print('train male:', train_male, '\\ttrain female:', train_female, '\\ttrain count:', train_count)\n",
    "print('valid male:', valid_male, '\\tvalid female:', valid_female, '\\tvalid count:', valid_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "continent-stopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_phase(phase_type, phase_count, phase_dataloader):\n",
    "    since = time.time()\n",
    "    phase_accuracy = 0.0\n",
    "    phase_loss = 0.0\n",
    "    # image_count = 0\n",
    "\n",
    "    for images, labels in phase_dataloader:\n",
    "        inputs = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimiser.zero_grad() # Zero out gradients when starting the training loop,\n",
    "                              # else gradient will point away from objective direction\n",
    "\n",
    "        with torch.set_grad_enabled(phase_type == 'train'):\n",
    "            # Forward\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            _, prediction = torch.max(outputs, 1)\n",
    "\n",
    "            if phase_type == 'train':\n",
    "                # Backward\n",
    "                loss.backward()\n",
    "                optimiser.step()\n",
    "\n",
    "        # Calc stats\n",
    "        phase_accuracy = phase_accuracy + (torch.sum(prediction == labels.data))\n",
    "        phase_loss = phase_loss + (loss.item() * images.size(0))\n",
    "\n",
    "        # Update image counter and elpased time\n",
    "        # time_elapsed = time.time() - since\n",
    "        # time_min = time_elapsed // 60\n",
    "        # time_sec = time_elapsed % 60\n",
    "        # print('\\r' + 'Image: ' + str(image_count), '\\tElpased Time:', '{:.0f}m {:.0f}s'.format(time_min, time_sec), end='')\n",
    "        # image_count+=1\n",
    "\n",
    "    epoch_accuracy = phase_accuracy.double() / phase_count\n",
    "    epoch_loss = phase_loss / phase_count\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    time_min = time_elapsed // 60\n",
    "    time_sec = time_elapsed % 60\n",
    "    \n",
    "    print('\\n{} \\tLoss: {:.4f} \\tAcc: {:.4f} \\tElpased Time: {:.0f}m {:.0f}s'.format(phase_type, epoch_loss, epoch_accuracy, time_min, time_sec ))\n",
    "    \n",
    "    return epoch_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "composite-avatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training\n",
    "def train(model, train_dataloader, valid_dataloader, optimiser, num_epochs):\n",
    "    best_acc = 0.0\n",
    "    epoch_accuracies = []\n",
    "    best_model = copy.deepcopy(model.state_dict())\n",
    "    since = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        print('Epoch', str(epoch + 1) + '/' + str(num_epochs))\n",
    "\n",
    "        # Train model phase\n",
    "        model.train()\n",
    "        run_phase('train', train_count, train_dataloader)\n",
    "\n",
    "        # Eval model phase\n",
    "        model.eval()\n",
    "        epoch_acc = run_phase('valid', valid_count, valid_dataloader)\n",
    "        \n",
    "        # Check performace\n",
    "        if epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "        # Record performance for analysis\n",
    "        epoch_accuracies.append(epoch_acc)\n",
    "\n",
    "        print('\\n')\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print(best_acc)\n",
    "    \n",
    "    return best_model, epoch_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "registered-savings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\n",
      "train \tLoss: 0.3976 \tAcc: 0.8302 \tElpased Time: 3m 18s\n",
      "\n",
      "valid \tLoss: 0.4141 \tAcc: 0.8180 \tElpased Time: 1m 5s\n",
      "\n",
      "\n",
      "Epoch 2/2\n",
      "\n",
      "train \tLoss: 0.3216 \tAcc: 0.8691 \tElpased Time: 3m 14s\n",
      "\n",
      "valid \tLoss: 0.3193 \tAcc: 0.8804 \tElpased Time: 1m 7s\n",
      "\n",
      "\n",
      "Training complete in 8m 44s\n",
      "tensor(0.8804, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "model, epoch_accuracies = train(model, train_dataloader, valid_dataloader, optimiser, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "early-apartment",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'trained_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "computational-conservative",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = [h.cpu().numpy() for h in epoch_accuracies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "digital-factory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Validation Accuracy vs. Number of Training Epochs\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "\n",
    "plt.plot(range(1,num_epochs+1),history,label=\"Pretrained\")\n",
    "plt.ylim((0,1.))\n",
    "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-transsexual",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
