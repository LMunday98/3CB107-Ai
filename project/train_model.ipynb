{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-northeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Luke Munday\n",
    "# 199116045\n",
    "# 3CB107 - AI Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-seller",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import glob\n",
    "import copy\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-cosmetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define run parmameters\n",
    "\n",
    "# Choose 'squeezenet', 'vgg' or 'resnet'\n",
    "\n",
    "model_name = \"squeezenet\"\n",
    "\n",
    "transform_image_size = 224\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "num_epochs = 15\n",
    "\n",
    "mode = 0o777"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-mailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data dict\n",
    "\n",
    "# Choose: 'palm' or 'dorsal'\n",
    "\n",
    "hand_type = 'palm'\n",
    "\n",
    "data_directory = \"./dataset_final/\" + hand_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genuine-classic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check device\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-pilot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase number of unique images by factor of 2 by horizontal flipping,\n",
    "# but cant vertically flip\n",
    "\n",
    "# Change colour channels from 0-255 to 0-1, numpy to tensors\n",
    "\n",
    "train_transformation = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(transform_image_size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        [0.485, 0.456, 0.406], # col = rgb channel\n",
    "        [0.229, 0.224, 0.225]) # row = mean deviation\n",
    "])\n",
    "\n",
    "valid_transformation = transforms.Compose([\n",
    "        transforms.Resize(transform_image_size),\n",
    "        transforms.CenterCrop(transform_image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            [0.485, 0.456, 0.406],\n",
    "            [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-structure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "\n",
    "train_dataset = datasets.ImageFolder(os.path.join(data_directory, 'train'), train_transformation)\n",
    "valid_dataset = datasets.ImageFolder(os.path.join(data_directory, 'valid'), valid_transformation)\n",
    "\n",
    "# Dataloader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True, # Shuffle is True so the model is not biased to some categories\n",
    "    num_workers=4 # How many sub processes to use for loading data into ram\n",
    ")\n",
    "\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-champagne",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_root = pathlib.Path(data_directory + '/train')\n",
    "data_classes = sorted([item.name.split('/')[-1] for item in train_root.iterdir()])\n",
    "num_classes = len(data_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-kennedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-stomach",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=True)\n",
    "        for parameter in model_ft.parameters():\n",
    "            parameter.requires_grad = False\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg16_bn(pretrained=True)\n",
    "        for parameter in model_ft.parameters():\n",
    "            parameter.requires_grad = False\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=True)\n",
    "        for parameter in model_ft.parameters():\n",
    "            parameter.requires_grad = False\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-female",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_ft.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-affiliate",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_update = model.parameters()\n",
    "print(\"Params to learn:\")\n",
    "params_to_update = []\n",
    "for name,param in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)\n",
    "        \n",
    "optimiser = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-original",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calc amount of training and validation images for each class\n",
    "\n",
    "train_male = len(glob.glob(data_directory + '/train/male/*.jpg'))\n",
    "train_female = len(glob.glob(data_directory + '/train/female/*.jpg'))\n",
    "train_count = train_male + train_female\n",
    "\n",
    "valid_male = len(glob.glob(data_directory + '/valid/male/*.jpg'))\n",
    "valid_female = len(glob.glob(data_directory + '/valid/female/*.jpg'))\n",
    "valid_count = valid_male + valid_female\n",
    "\n",
    "print('train male:', train_male, '\\ttrain female:', train_female, '\\ttrain count:', train_count)\n",
    "print('valid male:', valid_male, '\\tvalid female:', valid_female, '\\tvalid count:', valid_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-stopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_phase(phase_type, phase_count, phase_dataloader):\n",
    "    since = time.time()\n",
    "    phase_accuracy = 0.0\n",
    "    phase_loss = 0.0\n",
    "    # image_count = 0\n",
    "\n",
    "    for images, labels in phase_dataloader:\n",
    "        inputs = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimiser.zero_grad() # Zero out gradients when starting the training loop,\n",
    "                              # else gradient will point away from objective direction\n",
    "\n",
    "        with torch.set_grad_enabled(phase_type == 'train'):\n",
    "            # Forward\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            _, prediction = torch.max(outputs, 1)\n",
    "\n",
    "            if phase_type == 'train':\n",
    "                # Backward\n",
    "                loss.backward()\n",
    "                optimiser.step()\n",
    "\n",
    "        # Calc stats\n",
    "        phase_accuracy = phase_accuracy + (torch.sum(prediction == labels.data))\n",
    "        phase_loss = phase_loss + (loss.item() * images.size(0))\n",
    "\n",
    "        # Update image counter and elpased time\n",
    "        # time_elapsed = time.time() - since\n",
    "        # time_min = time_elapsed // 60\n",
    "        # time_sec = time_elapsed % 60\n",
    "        # print('\\r' + 'Image: ' + str(image_count), '\\tElpased Time:', '{:.0f}m {:.0f}s'.format(time_min, time_sec), end='')\n",
    "        # image_count+=1\n",
    "\n",
    "    epoch_accuracy = phase_accuracy.double() / phase_count\n",
    "    epoch_loss = phase_loss / phase_count\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    time_min = time_elapsed // 60\n",
    "    time_sec = time_elapsed % 60\n",
    "    \n",
    "    print('\\n{} \\tLoss: {:.4f} \\tAcc: {:.4f} \\tElpased Time: {:.0f}m {:.0f}s'.format(phase_type, epoch_loss, epoch_accuracy, time_min, time_sec ))\n",
    "    \n",
    "    return epoch_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-badge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training\n",
    "def train(model, train_dataloader, valid_dataloader, optimiser, num_epochs):\n",
    "    best_acc = 0.0\n",
    "    epoch_accuracies = []\n",
    "    best_model = copy.deepcopy(model.state_dict())\n",
    "    since = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        print('Epoch', str(epoch + 1) + '/' + str(num_epochs))\n",
    "\n",
    "        # Train model phase\n",
    "        model.train()\n",
    "        run_phase('train', train_count, train_dataloader)\n",
    "\n",
    "        # Eval model phase\n",
    "        model.eval()\n",
    "        epoch_acc = run_phase('valid', valid_count, valid_dataloader)\n",
    "        \n",
    "        # Check performace\n",
    "        if epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "        # Record performance for analysis\n",
    "        epoch_accuracies.append(epoch_acc)\n",
    "\n",
    "        print('\\n')\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best Accuracy: {:.4f}' .format(best_acc))\n",
    "    \n",
    "    return best_model, epoch_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-savings",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, epoch_accuracies = train(model, train_dataloader, valid_dataloader, optimiser, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-restoration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(folder_path):\n",
    "    try: \n",
    "        os.makedirs(os.path.join(folder_path), mode)\n",
    "    except OSError as error:\n",
    "        print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-apartment",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = 'trained_models/'\n",
    "create_dir(models_dir)\n",
    "models_dir = os.path.join(models_dir, model_name)\n",
    "torch.save(model, models_dir + ('_' + hand_type + '_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-drink",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = [h.cpu().numpy() for h in epoch_accuracies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-surge",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Validation Accuracy vs. Number of Training Epochs\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "\n",
    "plt.plot(range(1,num_epochs+1),history,label=\"Pretrained\")\n",
    "plt.ylim((0,1.))\n",
    "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "special-shade",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
